{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/running'),\n",
       " PosixPath('data/stairs'),\n",
       " PosixPath('data/walking'),\n",
       " PosixPath('data/idle')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = Path('./data')\n",
    "classes = list(data_folder.iterdir())\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "def flatten_sensor_frame(df): return df.values.flatten()\n",
    "data_list = []\n",
    "for class_folder in classes:\n",
    "    for file in class_folder.iterdir():\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        frame = flatten_sensor_frame(df)\n",
    "        record = list((frame)) + [str(class_folder)]\n",
    "        data_list.append(record)\n",
    "        \n",
    "        df['label'] = class_folder\n",
    "        dfs.append(df)\n",
    "\n",
    "    \n",
    "cols = [str(i) for i in range(90)] + ['label']\n",
    "full_df = pd.DataFrame(data=data_list, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.667141</td>\n",
       "      <td>-7.838616</td>\n",
       "      <td>-9.548077</td>\n",
       "      <td>4.017470</td>\n",
       "      <td>8.705317</td>\n",
       "      <td>-2.226607</td>\n",
       "      <td>22.357056</td>\n",
       "      <td>20.887016</td>\n",
       "      <td>-2.820370</td>\n",
       "      <td>17.922995</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.885855</td>\n",
       "      <td>11.310209</td>\n",
       "      <td>-8.939949</td>\n",
       "      <td>13.771448</td>\n",
       "      <td>9.825804</td>\n",
       "      <td>1.470040</td>\n",
       "      <td>-2.044648</td>\n",
       "      <td>6.689400</td>\n",
       "      <td>10.807426</td>\n",
       "      <td>data/running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.745177</td>\n",
       "      <td>23.415293</td>\n",
       "      <td>1.144428</td>\n",
       "      <td>3.744532</td>\n",
       "      <td>-9.035717</td>\n",
       "      <td>-2.892196</td>\n",
       "      <td>0.766145</td>\n",
       "      <td>21.092916</td>\n",
       "      <td>-0.928950</td>\n",
       "      <td>23.956383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.532289</td>\n",
       "      <td>15.782578</td>\n",
       "      <td>1.699883</td>\n",
       "      <td>14.168885</td>\n",
       "      <td>32.245110</td>\n",
       "      <td>3.390190</td>\n",
       "      <td>3.983952</td>\n",
       "      <td>-1.867477</td>\n",
       "      <td>-1.407790</td>\n",
       "      <td>data/running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.031445</td>\n",
       "      <td>18.406622</td>\n",
       "      <td>1.537078</td>\n",
       "      <td>3.600880</td>\n",
       "      <td>12.368446</td>\n",
       "      <td>2.217031</td>\n",
       "      <td>-0.354342</td>\n",
       "      <td>-13.206416</td>\n",
       "      <td>-7.254431</td>\n",
       "      <td>8.245631</td>\n",
       "      <td>...</td>\n",
       "      <td>4.151546</td>\n",
       "      <td>24.502260</td>\n",
       "      <td>-1.139640</td>\n",
       "      <td>-0.493206</td>\n",
       "      <td>-14.542381</td>\n",
       "      <td>-2.164358</td>\n",
       "      <td>2.442086</td>\n",
       "      <td>9.677363</td>\n",
       "      <td>-3.016694</td>\n",
       "      <td>data/running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.371682</td>\n",
       "      <td>-1.608903</td>\n",
       "      <td>-2.801216</td>\n",
       "      <td>25.718515</td>\n",
       "      <td>16.247053</td>\n",
       "      <td>-6.488286</td>\n",
       "      <td>-3.600879</td>\n",
       "      <td>6.684612</td>\n",
       "      <td>-2.375048</td>\n",
       "      <td>10.534488</td>\n",
       "      <td>...</td>\n",
       "      <td>17.056293</td>\n",
       "      <td>37.330395</td>\n",
       "      <td>5.621586</td>\n",
       "      <td>2.695871</td>\n",
       "      <td>11.626244</td>\n",
       "      <td>-1.082179</td>\n",
       "      <td>8.681376</td>\n",
       "      <td>12.124237</td>\n",
       "      <td>-4.946420</td>\n",
       "      <td>data/running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.624822</td>\n",
       "      <td>9.059659</td>\n",
       "      <td>4.390966</td>\n",
       "      <td>33.073500</td>\n",
       "      <td>33.202790</td>\n",
       "      <td>4.802769</td>\n",
       "      <td>3.792416</td>\n",
       "      <td>3.596091</td>\n",
       "      <td>-2.681506</td>\n",
       "      <td>-1.872266</td>\n",
       "      <td>...</td>\n",
       "      <td>1.187524</td>\n",
       "      <td>13.072341</td>\n",
       "      <td>-1.953669</td>\n",
       "      <td>1.441310</td>\n",
       "      <td>-14.585477</td>\n",
       "      <td>3.610456</td>\n",
       "      <td>6.028600</td>\n",
       "      <td>17.889475</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>data/running</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1         2          3          4         5          6  \\\n",
       "0   2.667141  -7.838616 -9.548077   4.017470   8.705317 -2.226607  22.357056   \n",
       "1  10.745177  23.415293  1.144428   3.744532  -9.035717 -2.892196   0.766145   \n",
       "2  22.031445  18.406622  1.537078   3.600880  12.368446  2.217031  -0.354342   \n",
       "3  10.371682  -1.608903 -2.801216  25.718515  16.247053 -6.488286  -3.600879   \n",
       "4   3.624822   9.059659  4.390966  33.073500  33.202790  4.802769   3.792416   \n",
       "\n",
       "           7         8          9  ...         81         82        83  \\\n",
       "0  20.887016 -2.820370  17.922995  ...  -0.885855  11.310209 -8.939949   \n",
       "1  21.092916 -0.928950  23.956383  ...   1.532289  15.782578  1.699883   \n",
       "2 -13.206416 -7.254431   8.245631  ...   4.151546  24.502260 -1.139640   \n",
       "3   6.684612 -2.375048  10.534488  ...  17.056293  37.330395  5.621586   \n",
       "4   3.596091 -2.681506  -1.872266  ...   1.187524  13.072341 -1.953669   \n",
       "\n",
       "          84         85        86        87         88         89  \\\n",
       "0  13.771448   9.825804  1.470040 -2.044648   6.689400  10.807426   \n",
       "1  14.168885  32.245110  3.390190  3.983952  -1.867477  -1.407790   \n",
       "2  -0.493206 -14.542381 -2.164358  2.442086   9.677363  -3.016694   \n",
       "3   2.695871  11.626244 -1.082179  8.681376  12.124237  -4.946420   \n",
       "4   1.441310 -14.585477  3.610456  6.028600  17.889475  -0.732626   \n",
       "\n",
       "          label  \n",
       "0  data/running  \n",
       "1  data/running  \n",
       "2  data/running  \n",
       "3  data/running  \n",
       "4  data/running  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6462, 91)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = full_df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f371d0c1510>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=counts.index, y=counts.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2num = dict(enumerate(full_df['label'].unique()))\n",
    "num2label = {n:i for i,n in label2num.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_df[[str(i) for i in range(90)] ]\n",
    "y = full_df['label'].map(num2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.667141</td>\n",
       "      <td>-7.838616</td>\n",
       "      <td>-9.548077</td>\n",
       "      <td>4.017470</td>\n",
       "      <td>8.705317</td>\n",
       "      <td>-2.226607</td>\n",
       "      <td>22.357056</td>\n",
       "      <td>20.887016</td>\n",
       "      <td>-2.820370</td>\n",
       "      <td>17.922995</td>\n",
       "      <td>...</td>\n",
       "      <td>12.430696</td>\n",
       "      <td>-0.885855</td>\n",
       "      <td>11.310209</td>\n",
       "      <td>-8.939949</td>\n",
       "      <td>13.771448</td>\n",
       "      <td>9.825804</td>\n",
       "      <td>1.470040</td>\n",
       "      <td>-2.044648</td>\n",
       "      <td>6.689400</td>\n",
       "      <td>10.807426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.745177</td>\n",
       "      <td>23.415293</td>\n",
       "      <td>1.144428</td>\n",
       "      <td>3.744532</td>\n",
       "      <td>-9.035717</td>\n",
       "      <td>-2.892196</td>\n",
       "      <td>0.766145</td>\n",
       "      <td>21.092916</td>\n",
       "      <td>-0.928950</td>\n",
       "      <td>23.956383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363919</td>\n",
       "      <td>1.532289</td>\n",
       "      <td>15.782578</td>\n",
       "      <td>1.699883</td>\n",
       "      <td>14.168885</td>\n",
       "      <td>32.245110</td>\n",
       "      <td>3.390190</td>\n",
       "      <td>3.983952</td>\n",
       "      <td>-1.867477</td>\n",
       "      <td>-1.407790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.031445</td>\n",
       "      <td>18.406622</td>\n",
       "      <td>1.537078</td>\n",
       "      <td>3.600880</td>\n",
       "      <td>12.368446</td>\n",
       "      <td>2.217031</td>\n",
       "      <td>-0.354342</td>\n",
       "      <td>-13.206416</td>\n",
       "      <td>-7.254431</td>\n",
       "      <td>8.245631</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.019023</td>\n",
       "      <td>4.151546</td>\n",
       "      <td>24.502260</td>\n",
       "      <td>-1.139640</td>\n",
       "      <td>-0.493206</td>\n",
       "      <td>-14.542381</td>\n",
       "      <td>-2.164358</td>\n",
       "      <td>2.442086</td>\n",
       "      <td>9.677363</td>\n",
       "      <td>-3.016694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.371682</td>\n",
       "      <td>-1.608903</td>\n",
       "      <td>-2.801216</td>\n",
       "      <td>25.718515</td>\n",
       "      <td>16.247053</td>\n",
       "      <td>-6.488286</td>\n",
       "      <td>-3.600879</td>\n",
       "      <td>6.684612</td>\n",
       "      <td>-2.375048</td>\n",
       "      <td>10.534488</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.200206</td>\n",
       "      <td>17.056293</td>\n",
       "      <td>37.330395</td>\n",
       "      <td>5.621586</td>\n",
       "      <td>2.695871</td>\n",
       "      <td>11.626244</td>\n",
       "      <td>-1.082179</td>\n",
       "      <td>8.681376</td>\n",
       "      <td>12.124237</td>\n",
       "      <td>-4.946420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.624822</td>\n",
       "      <td>9.059659</td>\n",
       "      <td>4.390966</td>\n",
       "      <td>33.073500</td>\n",
       "      <td>33.202790</td>\n",
       "      <td>4.802769</td>\n",
       "      <td>3.792416</td>\n",
       "      <td>3.596091</td>\n",
       "      <td>-2.681506</td>\n",
       "      <td>-1.872266</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.079719</td>\n",
       "      <td>1.187524</td>\n",
       "      <td>13.072341</td>\n",
       "      <td>-1.953669</td>\n",
       "      <td>1.441310</td>\n",
       "      <td>-14.585477</td>\n",
       "      <td>3.610456</td>\n",
       "      <td>6.028600</td>\n",
       "      <td>17.889475</td>\n",
       "      <td>-0.732626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6457</th>\n",
       "      <td>0.215478</td>\n",
       "      <td>0.090980</td>\n",
       "      <td>9.734824</td>\n",
       "      <td>0.234632</td>\n",
       "      <td>-0.095768</td>\n",
       "      <td>9.715671</td>\n",
       "      <td>0.239420</td>\n",
       "      <td>-0.009577</td>\n",
       "      <td>9.763555</td>\n",
       "      <td>0.239420</td>\n",
       "      <td>...</td>\n",
       "      <td>9.753978</td>\n",
       "      <td>0.248997</td>\n",
       "      <td>-0.019154</td>\n",
       "      <td>9.749189</td>\n",
       "      <td>0.244209</td>\n",
       "      <td>-0.019154</td>\n",
       "      <td>9.744401</td>\n",
       "      <td>0.234632</td>\n",
       "      <td>-0.004788</td>\n",
       "      <td>9.773131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6458</th>\n",
       "      <td>0.440533</td>\n",
       "      <td>2.360683</td>\n",
       "      <td>9.193734</td>\n",
       "      <td>2.341529</td>\n",
       "      <td>-0.995988</td>\n",
       "      <td>10.515334</td>\n",
       "      <td>-1.728614</td>\n",
       "      <td>-0.387861</td>\n",
       "      <td>10.017340</td>\n",
       "      <td>0.244209</td>\n",
       "      <td>...</td>\n",
       "      <td>9.739613</td>\n",
       "      <td>0.277727</td>\n",
       "      <td>-0.028730</td>\n",
       "      <td>9.768343</td>\n",
       "      <td>0.263362</td>\n",
       "      <td>-0.009577</td>\n",
       "      <td>9.763555</td>\n",
       "      <td>0.248997</td>\n",
       "      <td>-0.004788</td>\n",
       "      <td>9.768343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6459</th>\n",
       "      <td>-1.058237</td>\n",
       "      <td>4.807557</td>\n",
       "      <td>7.824251</td>\n",
       "      <td>-0.866701</td>\n",
       "      <td>4.946421</td>\n",
       "      <td>8.365341</td>\n",
       "      <td>-0.478840</td>\n",
       "      <td>5.152323</td>\n",
       "      <td>8.178593</td>\n",
       "      <td>-0.641646</td>\n",
       "      <td>...</td>\n",
       "      <td>7.196971</td>\n",
       "      <td>-0.656011</td>\n",
       "      <td>6.560113</td>\n",
       "      <td>7.235278</td>\n",
       "      <td>-0.445322</td>\n",
       "      <td>6.464345</td>\n",
       "      <td>7.800309</td>\n",
       "      <td>-0.416591</td>\n",
       "      <td>6.507440</td>\n",
       "      <td>7.091625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6460</th>\n",
       "      <td>-0.114922</td>\n",
       "      <td>-0.105345</td>\n",
       "      <td>9.806650</td>\n",
       "      <td>-0.081403</td>\n",
       "      <td>-0.124498</td>\n",
       "      <td>9.763555</td>\n",
       "      <td>-0.124498</td>\n",
       "      <td>-0.081403</td>\n",
       "      <td>9.840169</td>\n",
       "      <td>-0.081403</td>\n",
       "      <td>...</td>\n",
       "      <td>9.777920</td>\n",
       "      <td>-0.100556</td>\n",
       "      <td>-0.129287</td>\n",
       "      <td>9.777920</td>\n",
       "      <td>-0.081403</td>\n",
       "      <td>-0.124498</td>\n",
       "      <td>9.758766</td>\n",
       "      <td>-0.081403</td>\n",
       "      <td>-0.153229</td>\n",
       "      <td>9.763555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6461</th>\n",
       "      <td>0.306458</td>\n",
       "      <td>-0.076614</td>\n",
       "      <td>9.768343</td>\n",
       "      <td>0.253785</td>\n",
       "      <td>-0.062249</td>\n",
       "      <td>9.773131</td>\n",
       "      <td>0.258574</td>\n",
       "      <td>-0.052672</td>\n",
       "      <td>9.782708</td>\n",
       "      <td>0.268151</td>\n",
       "      <td>...</td>\n",
       "      <td>3.026271</td>\n",
       "      <td>1.182736</td>\n",
       "      <td>7.230490</td>\n",
       "      <td>6.804322</td>\n",
       "      <td>1.082179</td>\n",
       "      <td>7.015011</td>\n",
       "      <td>6.718130</td>\n",
       "      <td>0.852336</td>\n",
       "      <td>6.842629</td>\n",
       "      <td>6.957550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6462 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1         2          3          4          5  \\\n",
       "0      2.667141  -7.838616 -9.548077   4.017470   8.705317  -2.226607   \n",
       "1     10.745177  23.415293  1.144428   3.744532  -9.035717  -2.892196   \n",
       "2     22.031445  18.406622  1.537078   3.600880  12.368446   2.217031   \n",
       "3     10.371682  -1.608903 -2.801216  25.718515  16.247053  -6.488286   \n",
       "4      3.624822   9.059659  4.390966  33.073500  33.202790   4.802769   \n",
       "...         ...        ...       ...        ...        ...        ...   \n",
       "6457   0.215478   0.090980  9.734824   0.234632  -0.095768   9.715671   \n",
       "6458   0.440533   2.360683  9.193734   2.341529  -0.995988  10.515334   \n",
       "6459  -1.058237   4.807557  7.824251  -0.866701   4.946421   8.365341   \n",
       "6460  -0.114922  -0.105345  9.806650  -0.081403  -0.124498   9.763555   \n",
       "6461   0.306458  -0.076614  9.768343   0.253785  -0.062249   9.773131   \n",
       "\n",
       "              6          7          8          9  ...         80         81  \\\n",
       "0     22.357056  20.887016  -2.820370  17.922995  ...  12.430696  -0.885855   \n",
       "1      0.766145  21.092916  -0.928950  23.956383  ...   0.363919   1.532289   \n",
       "2     -0.354342 -13.206416  -7.254431   8.245631  ...  -6.019023   4.151546   \n",
       "3     -3.600879   6.684612  -2.375048  10.534488  ...  -5.200206  17.056293   \n",
       "4      3.792416   3.596091  -2.681506  -1.872266  ...  -4.079719   1.187524   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "6457   0.239420  -0.009577   9.763555   0.239420  ...   9.753978   0.248997   \n",
       "6458  -1.728614  -0.387861  10.017340   0.244209  ...   9.739613   0.277727   \n",
       "6459  -0.478840   5.152323   8.178593  -0.641646  ...   7.196971  -0.656011   \n",
       "6460  -0.124498  -0.081403   9.840169  -0.081403  ...   9.777920  -0.100556   \n",
       "6461   0.258574  -0.052672   9.782708   0.268151  ...   3.026271   1.182736   \n",
       "\n",
       "             82        83         84         85        86        87  \\\n",
       "0     11.310209 -8.939949  13.771448   9.825804  1.470040 -2.044648   \n",
       "1     15.782578  1.699883  14.168885  32.245110  3.390190  3.983952   \n",
       "2     24.502260 -1.139640  -0.493206 -14.542381 -2.164358  2.442086   \n",
       "3     37.330395  5.621586   2.695871  11.626244 -1.082179  8.681376   \n",
       "4     13.072341 -1.953669   1.441310 -14.585477  3.610456  6.028600   \n",
       "...         ...       ...        ...        ...       ...       ...   \n",
       "6457  -0.019154  9.749189   0.244209  -0.019154  9.744401  0.234632   \n",
       "6458  -0.028730  9.768343   0.263362  -0.009577  9.763555  0.248997   \n",
       "6459   6.560113  7.235278  -0.445322   6.464345  7.800309 -0.416591   \n",
       "6460  -0.129287  9.777920  -0.081403  -0.124498  9.758766 -0.081403   \n",
       "6461   7.230490  6.804322   1.082179   7.015011  6.718130  0.852336   \n",
       "\n",
       "             88         89  \n",
       "0      6.689400  10.807426  \n",
       "1     -1.867477  -1.407790  \n",
       "2      9.677363  -3.016694  \n",
       "3     12.124237  -4.946420  \n",
       "4     17.889475  -0.732626  \n",
       "...         ...        ...  \n",
       "6457  -0.004788   9.773131  \n",
       "6458  -0.004788   9.768343  \n",
       "6459   6.507440   7.091625  \n",
       "6460  -0.153229   9.763555  \n",
       "6461   6.842629   6.957550  \n",
       "\n",
       "[6462 rows x 90 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9822119102861562\n",
      "[[681   0   0   1]\n",
      " [  0  12  21   0]\n",
      " [  0   1 369   0]\n",
      " [  0   0   0 208]]\n",
      "0.9845320959010054\n",
      "[[682   0   0   0]\n",
      " [  0  13  20   0]\n",
      " [  0   0 370   0]\n",
      " [  0   0   0 208]]\n",
      "0.9814241486068112\n",
      "[[682   0   0   0]\n",
      " [  0   9  24   0]\n",
      " [  0   0 370   0]\n",
      " [  0   0   0 207]]\n",
      "0.9814241486068112\n",
      "[[680   0   0   1]\n",
      " [  0  14  19   0]\n",
      " [  0   4 366   0]\n",
      " [  0   0   0 208]]\n",
      "0.9814241486068112\n",
      "[[681   0   0   0]\n",
      " [  0  10  23   0]\n",
      " [  0   1 369   0]\n",
      " [  0   0   0 208]]\n"
     ]
    }
   ],
   "source": [
    "for train_ix, valid_ix in kfold.split(X, y):\n",
    "    # select rows\n",
    "    X_train, X_valid = X.loc[train_ix], X.loc[valid_ix]\n",
    "    y_train, y_valid = y.loc[train_ix], y.loc[valid_ix]\n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    \n",
    "    acc = accuracy_score(y_pred, y_valid)\n",
    "    print(acc)\n",
    "    print(confusion_matrix(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with binary sub-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = X.loc[train_ix], X.loc[valid_ix]\n",
    "y_train, y_valid = y.loc[train_ix], y.loc[valid_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "stairs_trn_ix = (y_train == 1) | (y_train == 2)\n",
    "\n",
    "y_train_stairs = y_train[stairs_trn_ix].copy()\n",
    "X_train_stairs = X_train[stairs_trn_ix]\n",
    "\n",
    "y_train_grouped = y_train.copy()\n",
    "y_train_grouped[stairs_trn_ix] = 2\n",
    "\n",
    "stairs_val_ix = (y_valid == 1) | (y_valid == 2)\n",
    "y_valid_stairs = y_valid[stairs_val_ix].copy()\n",
    "X_valid_stairs = X_valid[stairs_val_ix]\n",
    "\n",
    "y_valid_grouped = y_valid.copy()\n",
    "y_valid_grouped[stairs_val_ix] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1612, 90), (403, 90))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_stairs.shape, X_valid_stairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1480\n",
       "1     132\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_stairs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "stairs_clf = svm.SVC()\n",
    "stairs_clf.fit(X_train_stairs, y_train_stairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 16  17]\n",
      " [  2 368]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_valid_stairs, y_pred_stairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_grouped = clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9744582043343654"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_grouped, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[681,   0,   0,   0],\n",
       "       [  0,   0,  33,   0],\n",
       "       [  0,   0, 370,   0],\n",
       "       [  0,   0,   0, 208]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_valid, y_pred_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_ix = y_pred_grouped == 2\n",
    "\n",
    "X_valid_group = X_valid[group_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1,\n",
       "       2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_stairs_preds = stairs_clf.predict(X_valid_group)\n",
    "is_stairs_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_grouped[group_ix] = is_stairs_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[681,   0,   0,   0],\n",
       "       [  0,  16,  17,   0],\n",
       "       [  0,   2, 368,   0],\n",
       "       [  0,   0,   0, 208]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_valid, y_pred_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_valid_labels(X_train, y_train, X_valid):\n",
    "    stairs_trn_ix = (y_train == 1) | (y_train == 2)\n",
    "\n",
    "    y_train_stairs = y_train[stairs_trn_ix].copy()\n",
    "    X_train_stairs = X_train[stairs_trn_ix]\n",
    "\n",
    "    y_train_grouped = y_train.copy()\n",
    "    y_train_grouped[stairs_trn_ix] = 2\n",
    "    \n",
    "    \n",
    "    stairs_clf = svm.SVC()\n",
    "    stairs_clf.fit(X_train_stairs, y_train_stairs)\n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, y_train_grouped)\n",
    "    y_pred_grouped = clf.predict(X_valid)\n",
    "    \n",
    "    group_ix = y_pred_grouped == 2\n",
    "\n",
    "    X_valid_group = X_valid[group_ix]\n",
    "    is_stairs_preds = stairs_clf.predict(X_valid_group)\n",
    "    y_pred_grouped[group_ix] = is_stairs_preds\n",
    "    return y_pred_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[681,   0,   0,   0],\n",
       "       [  0,  16,  17,   0],\n",
       "       [  0,   2, 368,   0],\n",
       "       [  0,   0,   0, 208]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_grouped = predict_valid_labels(X_train, y_train, X_valid)\n",
    "confusion_matrix(y_valid, y_pred_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9845320959010054\n",
      "[[681   0   0   1]\n",
      " [  0  17  16   0]\n",
      " [  0   3 367   0]\n",
      " [  0   0   0 208]]\n",
      "0.9891724671307038\n",
      "[[682   0   0   0]\n",
      " [  0  19  14   0]\n",
      " [  0   0 370   0]\n",
      " [  0   0   0 208]]\n",
      "0.9860681114551083\n",
      "[[682   0   0   0]\n",
      " [  0  16  17   0]\n",
      " [  0   1 369   0]\n",
      " [  0   0   0 207]]\n",
      "0.9821981424148607\n",
      "[[680   0   0   1]\n",
      " [  0  15  18   0]\n",
      " [  0   4 366   0]\n",
      " [  0   0   0 208]]\n",
      "0.9852941176470589\n",
      "[[681   0   0   0]\n",
      " [  0  16  17   0]\n",
      " [  0   2 368   0]\n",
      " [  0   0   0 208]]\n"
     ]
    }
   ],
   "source": [
    "for train_ix, valid_ix in kfold.split(X, y):\n",
    "    # select rows\n",
    "    X_train, X_valid = X.loc[train_ix], X.loc[valid_ix]\n",
    "    y_train, y_valid = y.loc[train_ix], y.loc[valid_ix]\n",
    "    \n",
    "    y_pred = predict_valid_labels(X_train, y_train, X_valid)\n",
    "\n",
    "    \n",
    "    acc = accuracy_score(y_pred, y_valid)\n",
    "    print(acc)\n",
    "    print(confusion_matrix(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
