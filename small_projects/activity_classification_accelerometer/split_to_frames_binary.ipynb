{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_LENGTH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/running'),\n",
       " PosixPath('data/stairs'),\n",
       " PosixPath('data/walking'),\n",
       " PosixPath('data/idle')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = Path('./data')\n",
    "classes = list(data_folder.iterdir())\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "def flatten_sensor_frame(df): return df.values.flatten()\n",
    "data_list = []\n",
    "for class_folder in classes:\n",
    "    for file in class_folder.iterdir():\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        frame = flatten_sensor_frame(df)\n",
    "        record = list((frame)) + [str(class_folder)]\n",
    "        data_list.append(record)\n",
    "        \n",
    "        df['label'] = class_folder\n",
    "        dfs.append(df)\n",
    "\n",
    "    \n",
    "cols = [str(i) for i in range(90)] + ['label']\n",
    "full_df = pd.DataFrame(data=data_list, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_df[(full_df.label == 'data/walking') | (full_df.label == 'data/stairs')].copy().reset_index(drop=True)\n",
    "df['is_stairs'] = df['label'] == 'data/stairs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[str(i) for i in range(90)] ]\n",
    "y = df['is_stairs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_orig = X.copy()\n",
    "y_orig = y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1612, 90)\n",
      "(1612, 90)\n",
      "(1612, 90)\n",
      "(1612, 90)\n",
      "(1612, 90)\n",
      "F1 score mean: 0.64, std: 0.07\n"
     ]
    }
   ],
   "source": [
    "X = df[[str(i) for i in range(90)] ]\n",
    "y = df['is_stairs']\n",
    "\n",
    "f_scores = []\n",
    "\n",
    "for train_ix, valid_ix in kfold.split(X, y):\n",
    "    X_train, X_valid = X.loc[train_ix], X.loc[valid_ix]\n",
    "    y_train, y_valid = y.loc[train_ix], y.loc[valid_ix]\n",
    "    print(X_train.shape)\n",
    "    cls = svm.SVC()\n",
    "    cls.fit(X_train, y_train)\n",
    "    y_pred = cls.predict(X_valid)\n",
    "    f_scores.append(f1_score(y_valid, y_pred))\n",
    "    \n",
    "print(f'F1 score mean: {round(np.mean(f_scores), 2)}, std: {round(np.std(f_scores), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = X[:5]\n",
    "y_dev = y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.675165</td>\n",
       "      <td>-11.607090</td>\n",
       "      <td>-2.662352</td>\n",
       "      <td>-1.278504</td>\n",
       "      <td>-2.700659</td>\n",
       "      <td>0.924162</td>\n",
       "      <td>-4.424484</td>\n",
       "      <td>-10.726024</td>\n",
       "      <td>-1.082179</td>\n",
       "      <td>0.646435</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.330400</td>\n",
       "      <td>-7.350199</td>\n",
       "      <td>-12.670115</td>\n",
       "      <td>-1.460463</td>\n",
       "      <td>3.969586</td>\n",
       "      <td>-6.320692</td>\n",
       "      <td>9.255983</td>\n",
       "      <td>1.747767</td>\n",
       "      <td>2.920926</td>\n",
       "      <td>7.910443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.264915</td>\n",
       "      <td>-9.931149</td>\n",
       "      <td>-4.659116</td>\n",
       "      <td>0.991200</td>\n",
       "      <td>-10.903194</td>\n",
       "      <td>-8.183381</td>\n",
       "      <td>2.226608</td>\n",
       "      <td>-8.044517</td>\n",
       "      <td>-2.341529</td>\n",
       "      <td>-1.647211</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.202665</td>\n",
       "      <td>-3.102885</td>\n",
       "      <td>-4.644751</td>\n",
       "      <td>-2.456451</td>\n",
       "      <td>0.282516</td>\n",
       "      <td>-9.251195</td>\n",
       "      <td>-0.933739</td>\n",
       "      <td>-3.208230</td>\n",
       "      <td>-4.711789</td>\n",
       "      <td>0.885855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.431733</td>\n",
       "      <td>-8.274360</td>\n",
       "      <td>-1.738190</td>\n",
       "      <td>-1.786074</td>\n",
       "      <td>-7.996633</td>\n",
       "      <td>-3.327940</td>\n",
       "      <td>0.885855</td>\n",
       "      <td>-11.468226</td>\n",
       "      <td>5.544971</td>\n",
       "      <td>-0.770933</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.059013</td>\n",
       "      <td>3.466804</td>\n",
       "      <td>-5.406107</td>\n",
       "      <td>-2.633622</td>\n",
       "      <td>0.057461</td>\n",
       "      <td>-6.445191</td>\n",
       "      <td>-3.069367</td>\n",
       "      <td>5.880160</td>\n",
       "      <td>-6.900089</td>\n",
       "      <td>-3.509899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.124498</td>\n",
       "      <td>-9.442732</td>\n",
       "      <td>-0.842759</td>\n",
       "      <td>2.657564</td>\n",
       "      <td>-10.381259</td>\n",
       "      <td>0.665588</td>\n",
       "      <td>1.383849</td>\n",
       "      <td>-16.093824</td>\n",
       "      <td>-1.479617</td>\n",
       "      <td>1.771709</td>\n",
       "      <td>...</td>\n",
       "      <td>15.011644</td>\n",
       "      <td>6.871359</td>\n",
       "      <td>-2.738967</td>\n",
       "      <td>11.865664</td>\n",
       "      <td>5.521029</td>\n",
       "      <td>-0.158017</td>\n",
       "      <td>10.165780</td>\n",
       "      <td>3.394978</td>\n",
       "      <td>0.090980</td>\n",
       "      <td>5.243302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.478709</td>\n",
       "      <td>-22.160730</td>\n",
       "      <td>0.162806</td>\n",
       "      <td>5.272033</td>\n",
       "      <td>-25.546135</td>\n",
       "      <td>-8.652645</td>\n",
       "      <td>-2.264915</td>\n",
       "      <td>-17.348385</td>\n",
       "      <td>-2.834735</td>\n",
       "      <td>-7.426813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.866701</td>\n",
       "      <td>-1.958457</td>\n",
       "      <td>-8.978256</td>\n",
       "      <td>-4.625597</td>\n",
       "      <td>0.196325</td>\n",
       "      <td>-2.643199</td>\n",
       "      <td>-0.114922</td>\n",
       "      <td>-1.728614</td>\n",
       "      <td>-4.994304</td>\n",
       "      <td>-1.192312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1         2         3          4         5         6  \\\n",
       "0  0.675165 -11.607090 -2.662352 -1.278504  -2.700659  0.924162 -4.424484   \n",
       "1  2.264915  -9.931149 -4.659116  0.991200 -10.903194 -8.183381  2.226608   \n",
       "2  1.431733  -8.274360 -1.738190 -1.786074  -7.996633 -3.327940  0.885855   \n",
       "3 -0.124498  -9.442732 -0.842759  2.657564 -10.381259  0.665588  1.383849   \n",
       "4 -6.478709 -22.160730  0.162806  5.272033 -25.546135 -8.652645 -2.264915   \n",
       "\n",
       "           7         8         9  ...         80        81         82  \\\n",
       "0 -10.726024 -1.082179  0.646435  ...  -0.330400 -7.350199 -12.670115   \n",
       "1  -8.044517 -2.341529 -1.647211  ...  -2.202665 -3.102885  -4.644751   \n",
       "2 -11.468226  5.544971 -0.770933  ...  -2.059013  3.466804  -5.406107   \n",
       "3 -16.093824 -1.479617  1.771709  ...  15.011644  6.871359  -2.738967   \n",
       "4 -17.348385 -2.834735 -7.426813  ...  -0.866701 -1.958457  -8.978256   \n",
       "\n",
       "          83        84        85         86        87        88        89  \n",
       "0  -1.460463  3.969586 -6.320692   9.255983  1.747767  2.920926  7.910443  \n",
       "1  -2.456451  0.282516 -9.251195  -0.933739 -3.208230 -4.711789  0.885855  \n",
       "2  -2.633622  0.057461 -6.445191  -3.069367  5.880160 -6.900089 -3.509899  \n",
       "3  11.865664  5.521029 -0.158017  10.165780  3.394978  0.090980  5.243302  \n",
       "4  -4.625597  0.196325 -2.643199  -0.114922 -1.728614 -4.994304 -1.192312  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_acc_cols = [str(i) for i in range(0,89,3)]\n",
    "y_acc_cols = [str(i) for i in range(1,89,3)]\n",
    "z_acc_cols = [str(i) for i in range(2,90,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/running'),\n",
       " PosixPath('data/stairs'),\n",
       " PosixPath('data/walking'),\n",
       " PosixPath('data/idle')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "def flatten_sensor_frame(df): return df.values.flatten()\n",
    "for class_folder in [Path('./data/stairs'), Path('./data/walking')]:\n",
    "    for file in class_folder.iterdir():\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        df['label'] = class_folder\n",
    "        dfs.append(df)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <th>6</th>\n",
       "      <th>9</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>18</th>\n",
       "      <th>21</th>\n",
       "      <th>24</th>\n",
       "      <th>27</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>63</th>\n",
       "      <th>66</th>\n",
       "      <th>69</th>\n",
       "      <th>72</th>\n",
       "      <th>75</th>\n",
       "      <th>78</th>\n",
       "      <th>81</th>\n",
       "      <th>84</th>\n",
       "      <th>87</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.675165</td>\n",
       "      <td>-1.278504</td>\n",
       "      <td>-4.424484</td>\n",
       "      <td>0.646435</td>\n",
       "      <td>-1.623269</td>\n",
       "      <td>-4.323928</td>\n",
       "      <td>-5.228936</td>\n",
       "      <td>-3.088520</td>\n",
       "      <td>-3.021482</td>\n",
       "      <td>-11.238382</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.411672</td>\n",
       "      <td>-10.070012</td>\n",
       "      <td>-7.929596</td>\n",
       "      <td>-1.929727</td>\n",
       "      <td>-4.458003</td>\n",
       "      <td>-4.137180</td>\n",
       "      <td>1.829170</td>\n",
       "      <td>-7.350199</td>\n",
       "      <td>3.969586</td>\n",
       "      <td>1.747767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.264915</td>\n",
       "      <td>0.991200</td>\n",
       "      <td>2.226608</td>\n",
       "      <td>-1.647211</td>\n",
       "      <td>8.398860</td>\n",
       "      <td>2.494758</td>\n",
       "      <td>0.823605</td>\n",
       "      <td>-6.224924</td>\n",
       "      <td>1.273715</td>\n",
       "      <td>0.723049</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.278504</td>\n",
       "      <td>-0.330400</td>\n",
       "      <td>1.455675</td>\n",
       "      <td>1.613692</td>\n",
       "      <td>1.216255</td>\n",
       "      <td>-2.547430</td>\n",
       "      <td>-1.206678</td>\n",
       "      <td>-3.102885</td>\n",
       "      <td>0.282516</td>\n",
       "      <td>-3.208230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.431733</td>\n",
       "      <td>-1.786074</td>\n",
       "      <td>0.885855</td>\n",
       "      <td>-0.770933</td>\n",
       "      <td>6.670246</td>\n",
       "      <td>0.675165</td>\n",
       "      <td>7.771579</td>\n",
       "      <td>3.873819</td>\n",
       "      <td>3.193865</td>\n",
       "      <td>4.951209</td>\n",
       "      <td>...</td>\n",
       "      <td>4.936844</td>\n",
       "      <td>5.008670</td>\n",
       "      <td>0.210690</td>\n",
       "      <td>-0.478840</td>\n",
       "      <td>-0.153229</td>\n",
       "      <td>0.627281</td>\n",
       "      <td>1.177947</td>\n",
       "      <td>3.466804</td>\n",
       "      <td>0.057461</td>\n",
       "      <td>5.880160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.124498</td>\n",
       "      <td>2.657564</td>\n",
       "      <td>1.383849</td>\n",
       "      <td>1.771709</td>\n",
       "      <td>1.024718</td>\n",
       "      <td>2.628834</td>\n",
       "      <td>2.422932</td>\n",
       "      <td>-0.229843</td>\n",
       "      <td>2.949657</td>\n",
       "      <td>1.134852</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.082179</td>\n",
       "      <td>1.460463</td>\n",
       "      <td>-3.835511</td>\n",
       "      <td>1.776498</td>\n",
       "      <td>14.164097</td>\n",
       "      <td>10.864887</td>\n",
       "      <td>9.064447</td>\n",
       "      <td>6.871359</td>\n",
       "      <td>5.521029</td>\n",
       "      <td>3.394978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.478709</td>\n",
       "      <td>5.272033</td>\n",
       "      <td>-2.264915</td>\n",
       "      <td>-7.426813</td>\n",
       "      <td>-0.694318</td>\n",
       "      <td>-0.632069</td>\n",
       "      <td>3.782839</td>\n",
       "      <td>-0.507571</td>\n",
       "      <td>1.369483</td>\n",
       "      <td>2.494758</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.454898</td>\n",
       "      <td>9.035717</td>\n",
       "      <td>-1.273715</td>\n",
       "      <td>-0.794875</td>\n",
       "      <td>2.336741</td>\n",
       "      <td>-6.157887</td>\n",
       "      <td>-6.904877</td>\n",
       "      <td>-1.958457</td>\n",
       "      <td>0.196325</td>\n",
       "      <td>-1.728614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         3         6         9        12        15        18  \\\n",
       "0  0.675165 -1.278504 -4.424484  0.646435 -1.623269 -4.323928 -5.228936   \n",
       "1  2.264915  0.991200  2.226608 -1.647211  8.398860  2.494758  0.823605   \n",
       "2  1.431733 -1.786074  0.885855 -0.770933  6.670246  0.675165  7.771579   \n",
       "3 -0.124498  2.657564  1.383849  1.771709  1.024718  2.628834  2.422932   \n",
       "4 -6.478709  5.272033 -2.264915 -7.426813 -0.694318 -0.632069  3.782839   \n",
       "\n",
       "         21        24         27  ...        60         63        66  \\\n",
       "0 -3.088520 -3.021482 -11.238382  ... -6.411672 -10.070012 -7.929596   \n",
       "1 -6.224924  1.273715   0.723049  ... -1.278504  -0.330400  1.455675   \n",
       "2  3.873819  3.193865   4.951209  ...  4.936844   5.008670  0.210690   \n",
       "3 -0.229843  2.949657   1.134852  ... -1.082179   1.460463 -3.835511   \n",
       "4 -0.507571  1.369483   2.494758  ... -0.454898   9.035717 -1.273715   \n",
       "\n",
       "         69         72         75        78        81        84        87  \n",
       "0 -1.929727  -4.458003  -4.137180  1.829170 -7.350199  3.969586  1.747767  \n",
       "1  1.613692   1.216255  -2.547430 -1.206678 -3.102885  0.282516 -3.208230  \n",
       "2 -0.478840  -0.153229   0.627281  1.177947  3.466804  0.057461  5.880160  \n",
       "3  1.776498  14.164097  10.864887  9.064447  6.871359  5.521029  3.394978  \n",
       "4 -0.794875   2.336741  -6.157887 -6.904877 -1.958457  0.196325 -1.728614  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev[x_acc_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accelerometer_X</th>\n",
       "      <th>accelerometer_Y</th>\n",
       "      <th>accelerometer_Z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.675165</td>\n",
       "      <td>-11.607090</td>\n",
       "      <td>-2.662352</td>\n",
       "      <td>data/stairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.278504</td>\n",
       "      <td>-2.700659</td>\n",
       "      <td>0.924162</td>\n",
       "      <td>data/stairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.424484</td>\n",
       "      <td>-10.726024</td>\n",
       "      <td>-1.082179</td>\n",
       "      <td>data/stairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.646435</td>\n",
       "      <td>-0.641646</td>\n",
       "      <td>-1.048660</td>\n",
       "      <td>data/stairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.623269</td>\n",
       "      <td>-6.603208</td>\n",
       "      <td>0.071826</td>\n",
       "      <td>data/stairs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accelerometer_X  accelerometer_Y  accelerometer_Z        label\n",
       "0         0.675165       -11.607090        -2.662352  data/stairs\n",
       "1        -1.278504        -2.700659         0.924162  data/stairs\n",
       "2        -4.424484       -10.726024        -1.082179  data/stairs\n",
       "3         0.646435        -0.641646        -1.048660  data/stairs\n",
       "4        -1.623269        -6.603208         0.071826  data/stairs"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.675165</td>\n",
       "      <td>-11.607090</td>\n",
       "      <td>-2.662352</td>\n",
       "      <td>-1.278504</td>\n",
       "      <td>-2.700659</td>\n",
       "      <td>0.924162</td>\n",
       "      <td>-4.424484</td>\n",
       "      <td>-10.726024</td>\n",
       "      <td>-1.082179</td>\n",
       "      <td>0.646435</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.330400</td>\n",
       "      <td>-7.350199</td>\n",
       "      <td>-12.670115</td>\n",
       "      <td>-1.460463</td>\n",
       "      <td>3.969586</td>\n",
       "      <td>-6.320692</td>\n",
       "      <td>9.255983</td>\n",
       "      <td>1.747767</td>\n",
       "      <td>2.920926</td>\n",
       "      <td>7.910443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.264915</td>\n",
       "      <td>-9.931149</td>\n",
       "      <td>-4.659116</td>\n",
       "      <td>0.991200</td>\n",
       "      <td>-10.903194</td>\n",
       "      <td>-8.183381</td>\n",
       "      <td>2.226608</td>\n",
       "      <td>-8.044517</td>\n",
       "      <td>-2.341529</td>\n",
       "      <td>-1.647211</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.202665</td>\n",
       "      <td>-3.102885</td>\n",
       "      <td>-4.644751</td>\n",
       "      <td>-2.456451</td>\n",
       "      <td>0.282516</td>\n",
       "      <td>-9.251195</td>\n",
       "      <td>-0.933739</td>\n",
       "      <td>-3.208230</td>\n",
       "      <td>-4.711789</td>\n",
       "      <td>0.885855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.431733</td>\n",
       "      <td>-8.274360</td>\n",
       "      <td>-1.738190</td>\n",
       "      <td>-1.786074</td>\n",
       "      <td>-7.996633</td>\n",
       "      <td>-3.327940</td>\n",
       "      <td>0.885855</td>\n",
       "      <td>-11.468226</td>\n",
       "      <td>5.544971</td>\n",
       "      <td>-0.770933</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.059013</td>\n",
       "      <td>3.466804</td>\n",
       "      <td>-5.406107</td>\n",
       "      <td>-2.633622</td>\n",
       "      <td>0.057461</td>\n",
       "      <td>-6.445191</td>\n",
       "      <td>-3.069367</td>\n",
       "      <td>5.880160</td>\n",
       "      <td>-6.900089</td>\n",
       "      <td>-3.509899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.124498</td>\n",
       "      <td>-9.442732</td>\n",
       "      <td>-0.842759</td>\n",
       "      <td>2.657564</td>\n",
       "      <td>-10.381259</td>\n",
       "      <td>0.665588</td>\n",
       "      <td>1.383849</td>\n",
       "      <td>-16.093824</td>\n",
       "      <td>-1.479617</td>\n",
       "      <td>1.771709</td>\n",
       "      <td>...</td>\n",
       "      <td>15.011644</td>\n",
       "      <td>6.871359</td>\n",
       "      <td>-2.738967</td>\n",
       "      <td>11.865664</td>\n",
       "      <td>5.521029</td>\n",
       "      <td>-0.158017</td>\n",
       "      <td>10.165780</td>\n",
       "      <td>3.394978</td>\n",
       "      <td>0.090980</td>\n",
       "      <td>5.243302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.478709</td>\n",
       "      <td>-22.160730</td>\n",
       "      <td>0.162806</td>\n",
       "      <td>5.272033</td>\n",
       "      <td>-25.546135</td>\n",
       "      <td>-8.652645</td>\n",
       "      <td>-2.264915</td>\n",
       "      <td>-17.348385</td>\n",
       "      <td>-2.834735</td>\n",
       "      <td>-7.426813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.866701</td>\n",
       "      <td>-1.958457</td>\n",
       "      <td>-8.978256</td>\n",
       "      <td>-4.625597</td>\n",
       "      <td>0.196325</td>\n",
       "      <td>-2.643199</td>\n",
       "      <td>-0.114922</td>\n",
       "      <td>-1.728614</td>\n",
       "      <td>-4.994304</td>\n",
       "      <td>-1.192312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>-0.852336</td>\n",
       "      <td>-7.240066</td>\n",
       "      <td>-0.914585</td>\n",
       "      <td>-2.341529</td>\n",
       "      <td>-9.883265</td>\n",
       "      <td>-0.938527</td>\n",
       "      <td>-3.974375</td>\n",
       "      <td>-21.327547</td>\n",
       "      <td>-6.823475</td>\n",
       "      <td>-5.674258</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.018892</td>\n",
       "      <td>-5.995081</td>\n",
       "      <td>-9.749189</td>\n",
       "      <td>-0.857124</td>\n",
       "      <td>-1.206678</td>\n",
       "      <td>-19.426552</td>\n",
       "      <td>-2.178723</td>\n",
       "      <td>0.861913</td>\n",
       "      <td>-15.878345</td>\n",
       "      <td>-3.342306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0.584185</td>\n",
       "      <td>1.134852</td>\n",
       "      <td>1.273715</td>\n",
       "      <td>-2.245761</td>\n",
       "      <td>-7.393295</td>\n",
       "      <td>1.043872</td>\n",
       "      <td>-0.799663</td>\n",
       "      <td>-3.878607</td>\n",
       "      <td>2.863465</td>\n",
       "      <td>-2.442086</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.489193</td>\n",
       "      <td>-2.245761</td>\n",
       "      <td>-7.024587</td>\n",
       "      <td>-7.177817</td>\n",
       "      <td>-0.478840</td>\n",
       "      <td>-12.162544</td>\n",
       "      <td>-1.484405</td>\n",
       "      <td>-0.215478</td>\n",
       "      <td>-1.326388</td>\n",
       "      <td>0.617704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>1.187524</td>\n",
       "      <td>-15.638926</td>\n",
       "      <td>-3.145981</td>\n",
       "      <td>1.407791</td>\n",
       "      <td>-10.319010</td>\n",
       "      <td>1.891419</td>\n",
       "      <td>-2.767697</td>\n",
       "      <td>-15.911864</td>\n",
       "      <td>6.272809</td>\n",
       "      <td>2.226608</td>\n",
       "      <td>...</td>\n",
       "      <td>5.621586</td>\n",
       "      <td>-4.515464</td>\n",
       "      <td>-0.325611</td>\n",
       "      <td>3.806781</td>\n",
       "      <td>-1.939303</td>\n",
       "      <td>-6.823475</td>\n",
       "      <td>-4.127603</td>\n",
       "      <td>0.646435</td>\n",
       "      <td>-9.902418</td>\n",
       "      <td>-0.703895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>1.647211</td>\n",
       "      <td>-3.912125</td>\n",
       "      <td>2.264915</td>\n",
       "      <td>4.927267</td>\n",
       "      <td>-7.240066</td>\n",
       "      <td>2.092532</td>\n",
       "      <td>-1.436521</td>\n",
       "      <td>-16.745047</td>\n",
       "      <td>4.932056</td>\n",
       "      <td>5.497087</td>\n",
       "      <td>...</td>\n",
       "      <td>4.486734</td>\n",
       "      <td>6.943185</td>\n",
       "      <td>-12.061988</td>\n",
       "      <td>-2.949656</td>\n",
       "      <td>4.745308</td>\n",
       "      <td>-6.789956</td>\n",
       "      <td>15.102624</td>\n",
       "      <td>4.587291</td>\n",
       "      <td>-12.971785</td>\n",
       "      <td>-2.308010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>-6.560112</td>\n",
       "      <td>-15.083470</td>\n",
       "      <td>-1.359906</td>\n",
       "      <td>-1.383848</td>\n",
       "      <td>-8.480263</td>\n",
       "      <td>32.312145</td>\n",
       "      <td>-2.786851</td>\n",
       "      <td>-12.694057</td>\n",
       "      <td>0.191536</td>\n",
       "      <td>-13.421895</td>\n",
       "      <td>...</td>\n",
       "      <td>1.244985</td>\n",
       "      <td>-1.422156</td>\n",
       "      <td>-12.559982</td>\n",
       "      <td>-5.679046</td>\n",
       "      <td>-3.485957</td>\n",
       "      <td>-12.157756</td>\n",
       "      <td>-0.976834</td>\n",
       "      <td>-5.406107</td>\n",
       "      <td>0.383072</td>\n",
       "      <td>-16.869543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2015 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1         2         3          4          5         6  \\\n",
       "0     0.675165 -11.607090 -2.662352 -1.278504  -2.700659   0.924162 -4.424484   \n",
       "1     2.264915  -9.931149 -4.659116  0.991200 -10.903194  -8.183381  2.226608   \n",
       "2     1.431733  -8.274360 -1.738190 -1.786074  -7.996633  -3.327940  0.885855   \n",
       "3    -0.124498  -9.442732 -0.842759  2.657564 -10.381259   0.665588  1.383849   \n",
       "4    -6.478709 -22.160730  0.162806  5.272033 -25.546135  -8.652645 -2.264915   \n",
       "...        ...        ...       ...       ...        ...        ...       ...   \n",
       "2010 -0.852336  -7.240066 -0.914585 -2.341529  -9.883265  -0.938527 -3.974375   \n",
       "2011  0.584185   1.134852  1.273715 -2.245761  -7.393295   1.043872 -0.799663   \n",
       "2012  1.187524 -15.638926 -3.145981  1.407791 -10.319010   1.891419 -2.767697   \n",
       "2013  1.647211  -3.912125  2.264915  4.927267  -7.240066   2.092532 -1.436521   \n",
       "2014 -6.560112 -15.083470 -1.359906 -1.383848  -8.480263  32.312145 -2.786851   \n",
       "\n",
       "              7         8          9  ...         80        81         82  \\\n",
       "0    -10.726024 -1.082179   0.646435  ...  -0.330400 -7.350199 -12.670115   \n",
       "1     -8.044517 -2.341529  -1.647211  ...  -2.202665 -3.102885  -4.644751   \n",
       "2    -11.468226  5.544971  -0.770933  ...  -2.059013  3.466804  -5.406107   \n",
       "3    -16.093824 -1.479617   1.771709  ...  15.011644  6.871359  -2.738967   \n",
       "4    -17.348385 -2.834735  -7.426813  ...  -0.866701 -1.958457  -8.978256   \n",
       "...         ...       ...        ...  ...        ...       ...        ...   \n",
       "2010 -21.327547 -6.823475  -5.674258  ... -12.018892 -5.995081  -9.749189   \n",
       "2011  -3.878607  2.863465  -2.442086  ...  -1.489193 -2.245761  -7.024587   \n",
       "2012 -15.911864  6.272809   2.226608  ...   5.621586 -4.515464  -0.325611   \n",
       "2013 -16.745047  4.932056   5.497087  ...   4.486734  6.943185 -12.061988   \n",
       "2014 -12.694057  0.191536 -13.421895  ...   1.244985 -1.422156 -12.559982   \n",
       "\n",
       "             83        84         85         86        87         88  \\\n",
       "0     -1.460463  3.969586  -6.320692   9.255983  1.747767   2.920926   \n",
       "1     -2.456451  0.282516  -9.251195  -0.933739 -3.208230  -4.711789   \n",
       "2     -2.633622  0.057461  -6.445191  -3.069367  5.880160  -6.900089   \n",
       "3     11.865664  5.521029  -0.158017  10.165780  3.394978   0.090980   \n",
       "4     -4.625597  0.196325  -2.643199  -0.114922 -1.728614  -4.994304   \n",
       "...         ...       ...        ...        ...       ...        ...   \n",
       "2010  -0.857124 -1.206678 -19.426552  -2.178723  0.861913 -15.878345   \n",
       "2011  -7.177817 -0.478840 -12.162544  -1.484405 -0.215478  -1.326388   \n",
       "2012   3.806781 -1.939303  -6.823475  -4.127603  0.646435  -9.902418   \n",
       "2013  -2.949656  4.745308  -6.789956  15.102624  4.587291 -12.971785   \n",
       "2014  -5.679046 -3.485957 -12.157756  -0.976834 -5.406107   0.383072   \n",
       "\n",
       "             89  \n",
       "0      7.910443  \n",
       "1      0.885855  \n",
       "2     -3.509899  \n",
       "3      5.243302  \n",
       "4     -1.192312  \n",
       "...         ...  \n",
       "2010  -3.342306  \n",
       "2011   0.617704  \n",
       "2012  -0.703895  \n",
       "2013  -2.308010  \n",
       "2014 -16.869543  \n",
       "\n",
       "[2015 rows x 90 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2015, 30)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_part = X[x_acc_cols].values\n",
    "y_part = X[y_acc_cols].values\n",
    "z_part = X[z_acc_cols].values\n",
    "# a_part = X_train[acceleration_cols].values\n",
    "y_part.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2015, 3, 30)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.stack([x_part, y_part, z_part], axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2015,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FrameSlidingClassifier_SVM():\n",
    "#     def __init__(self, window_size=20, frame_length):\n",
    "#         self.window_size=window_size\n",
    "        \n",
    "#     def fit(self, X, y):\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_frames_to_windows(X, window_size = 20):\n",
    "    frame_length = X.shape[-1]\n",
    "    n_windows = frame_length - window_size + 1\n",
    "    i = 0\n",
    "\n",
    "    X_extended = []\n",
    "    for i in range(0, n_windows):\n",
    "        X_extended.append(X[:, :, i:window_size+i])\n",
    "\n",
    "    X_extended = np.vstack(X_extended)\n",
    "    return X_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[5, 3, 4, 0],\n",
       "        [1, 3, 5, 0],\n",
       "        [0, 1, 4, 5]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "sample_X = np.random.randint(6, size=(1,3,4))\n",
    "sample_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[5, 3, 4],\n",
       "        [1, 3, 5],\n",
       "        [0, 1, 4]],\n",
       "\n",
       "       [[3, 4, 0],\n",
       "        [3, 5, 0],\n",
       "        [1, 4, 5]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_windows = split_frames_to_windows(sample_X, window_size=3)\n",
    "assert len(sample_windows)      == 2 # we expect to get 2 windows\n",
    "assert sample_windows.shape[1:] == (3,3) # we expect each window to be 3x3\n",
    "\n",
    "sample_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_predictions_incorrect(y_pred, n_windows):\n",
    "    n_preds = int(len(y_pred)/n_windows)\n",
    "    y_pred_collapsed = []\n",
    "    for i in range(n_preds):\n",
    "        window_preds = y_pred[(i*n_windows):(i+1)*n_windows]\n",
    "        y_pred_collapsed.append(np.mean(window_preds))\n",
    "    return np.array(y_pred_collapsed)\n",
    "\n",
    "\n",
    "def fold_predictions(y_pred, n_windows):\n",
    "    y_pred = y_pred.reshape(n_windows, -1)\n",
    "    return y_pred.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_preds = np.array([1, 0, 1, 1, 0, 0])\n",
    "expected_preds = np.array([1., 0., .5])\n",
    "\n",
    "actual_preds = fold_predictions(sample_preds, n_windows=2)\n",
    "\n",
    "assert np.allclose(actual_preds, expected_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_ts_parts(X):\n",
    "    x_part = X[x_acc_cols].values\n",
    "    y_part = X[y_acc_cols].values\n",
    "    z_part = X[z_acc_cols].values\n",
    "    features = np.stack([x_part, y_part, z_part], axis=1)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score mean: 0.64, std: 0.07\n"
     ]
    }
   ],
   "source": [
    "X = df[[str(i) for i in range(90)] ]\n",
    "y = df['is_stairs']\n",
    "\n",
    "f_scores = []\n",
    "\n",
    "for train_ix, valid_ix in kfold.split(X, y):\n",
    "    X_train, X_valid = X.loc[train_ix], X.loc[valid_ix]\n",
    "    y_train, y_valid = y.loc[train_ix], y.loc[valid_ix]\n",
    "    \n",
    "    cls = svm.SVC()\n",
    "    cls.fit(X_train, y_train)\n",
    "    y_pred = cls.predict(X_valid)\n",
    "    f_scores.append(f1_score(y_valid, y_pred))\n",
    "    \n",
    "print(f'F1 score mean: {round(np.mean(f_scores), 2)}, std: {round(np.std(f_scores), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2015, 3, 30)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assemble_ts_parts(X_orig).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "        ...  \n",
       "2010    False\n",
       "2011    False\n",
       "2012    False\n",
       "2013    False\n",
       "2014    False\n",
       "Name: is_stairs, Length: 2015, dtype: bool"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4030,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_orig.repeat(n_windows).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 2, 1, 2])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(np.array([1,2]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 29\n",
    "n_windows = FRAME_LENGTH - window_size + 1\n",
    "X_extended = split_frames_to_windows(assemble_ts_parts(df[[str(i) for i in range(90)] ]), window_size=window_size)\n",
    "y_extended = np.tile(y_orig, n_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[734   6]\n",
      " [ 31  35]]\n",
      "[[736   4]\n",
      " [ 28  38]]\n",
      "[[739   1]\n",
      " [ 35  31]]\n",
      "[[733   7]\n",
      " [ 28  38]]\n",
      "[[734   6]\n",
      " [ 29  37]]\n",
      "F1 score mean: 0.67, std: 0.02\n"
     ]
    }
   ],
   "source": [
    "X = X_extended.reshape(len(X_extended), -1)\n",
    "y = y_extended\n",
    "\n",
    "f_scores = []\n",
    "\n",
    "for train_ix, valid_ix in kfold.split(X, y):\n",
    "    X_train, X_valid = X[train_ix], X[valid_ix]\n",
    "    y_train, y_valid = y[train_ix], y[valid_ix]\n",
    "    \n",
    "    cls = svm.SVC()\n",
    "    cls.fit(X_train, y_train)\n",
    "    y_pred = cls.predict(X_valid)\n",
    "    f_scores.append(f1_score(y_valid, y_pred))\n",
    "    \n",
    "    print(confusion_matrix(y_valid, y_pred))\n",
    "    \n",
    "print(f'F1 score mean: {round(np.mean(f_scores), 2)}, std: {round(np.std(f_scores), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f_score(window_size):\n",
    "    n_windows = FRAME_LENGTH - window_size + 1\n",
    "    X_extended = split_frames_to_windows(assemble_ts_parts(df[[str(i) for i in range(90)] ]), window_size=window_size)\n",
    "    y_extended = np.tile(y_orig, n_windows)\n",
    "    \n",
    "    X = X_extended.reshape(len(X_extended), -1)\n",
    "    y = y_extended\n",
    "\n",
    "    f_scores = []\n",
    "\n",
    "    for train_ix, valid_ix in kfold.split(X, y):\n",
    "        X_train, X_valid = X[train_ix], X[valid_ix]\n",
    "        y_train, y_valid = y[train_ix], y[valid_ix]\n",
    "\n",
    "        cls = svm.SVC()\n",
    "        cls.fit(X_train, y_train)\n",
    "        y_pred = cls.predict(X_valid)\n",
    "        f_scores.append(f1_score(y_valid, y_pred))\n",
    "\n",
    "    return np.mean(f_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f270ec9bcff44b929154bd76c67b6f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "window_sizes = list(range(10, 31))\n",
    "f_scores = []\n",
    "\n",
    "for window_size in tqdm(window_sizes):\n",
    "    f_scores.append(get_f_score(window_size))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe306074110>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x=window_sizes, y=f_scores)\n",
    "sns.scatterplot(x=window_sizes, y=f_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score mean: 0.64, std: 0.07\n"
     ]
    }
   ],
   "source": [
    "X = df[[str(i) for i in range(90)] ]\n",
    "y = df['is_stairs']\n",
    "\n",
    "f_scores = []\n",
    "\n",
    "for train_ix, valid_ix in kfold.split(X, y):\n",
    "    X_train, X_valid = X.loc[train_ix], X.loc[valid_ix]\n",
    "    y_train, y_valid = y.loc[train_ix], y.loc[valid_ix]\n",
    "    \n",
    "    cls = svm.SVC()\n",
    "    cls.fit(X_train, y_train)\n",
    "    y_pred = cls.predict(X_valid)\n",
    "    f_scores.append(f1_score(y_valid, y_pred))\n",
    "    \n",
    "print(f'F1 score mean: {round(np.mean(f_scores), 2)}, std: {round(np.std(f_scores), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = X_orig.loc[train_ix], X_orig.loc[valid_ix]\n",
    "y_train, y_valid = y[train_ix], y[valid_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1612, 90)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1612, 3, 30)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_frames = assemble_ts_parts(X_train)\n",
    "ts_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 20\n",
    "n_windows = FRAME_LENGTH - window_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17732, 60)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_extended = split_frames_to_windows(ts_frames)\n",
    "X_train_extended = X_train_extended.reshape(len(X_train_extended), -1)\n",
    "X_train_extended.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17732,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_extended = np.tile(y_train, n_windows)\n",
    "y_train_extended.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.fit(X_train_extended, y_train_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4433, 60)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_extended = assemble_ts_parts(X_valid)\n",
    "X_valid_extended = split_frames_to_windows(X_valid_extended, window_size=window_size)\n",
    "X_valid_extended = X_valid_extended.reshape(len(X_valid_extended), -1)\n",
    "X_valid_extended.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403, 90)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_extended = cls.predict(X_valid_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4433,)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_extended.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403,)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = fold_predictions(y_pred_extended, n_windows=n_windows)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403,)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[345,  25],\n",
       "       [ 30,   3]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_valid, y_pred>.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score mean: 0.09, std: 0.0\n"
     ]
    }
   ],
   "source": [
    "window_size = 20\n",
    "threshold = .5\n",
    "n_windows = FRAME_LENGTH - window_size + 1\n",
    "\n",
    "X = df[[str(i) for i in range(90)] ]\n",
    "y = df['is_stairs']\n",
    "\n",
    "f_scores = []\n",
    "\n",
    "for train_ix, valid_ix in kfold.split(X, y):\n",
    "    X_train, X_valid = X.loc[train_ix], X.loc[valid_ix]\n",
    "    y_train, y_valid = y.loc[train_ix], y.loc[valid_ix]\n",
    "    \n",
    "    \n",
    "    X_train_extended = split_frames_to_windows(ts_frames)\n",
    "    X_train_extended = X_train_extended.reshape(len(X_train_extended), -1)\n",
    "    y_train_extended = np.tile(y_train, n_windows)\n",
    "    \n",
    "    cls = svm.SVC()\n",
    "    cls.fit(X_train_extended, y_train_extended)\n",
    "    X_valid_extended = assemble_ts_parts(X_valid)\n",
    "    X_valid_extended = split_frames_to_windows(X_valid_extended, window_size=window_size)\n",
    "    X_valid_extended = X_valid_extended.reshape(len(X_valid_extended), -1)\n",
    "    \n",
    "    y_pred_extended = cls.predict(X_valid_extended)\n",
    "    y_pred = fold_predictions(y_pred_extended, n_windows=n_windows)\n",
    "    y_pred = y_pred > threshold\n",
    "    f_scores.append(f1_score(y_valid, y_pred))\n",
    "    \n",
    "print(f'F1 score mean: {round(np.mean(f_scores), 2)}, std: {round(np.std(f_scores), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1612, 90)\n",
      "(1612, 90)\n",
      "(1612, 90)\n",
      "(1612, 90)\n",
      "(1612, 90)\n",
      "F1 score mean: 0.74, std: 0.08\n"
     ]
    }
   ],
   "source": [
    "window_size = 30\n",
    "threshold = .5\n",
    "n_windows = FRAME_LENGTH - window_size + 1\n",
    "\n",
    "X = df[[str(i) for i in range(90)] ]\n",
    "y = df['is_stairs']\n",
    "\n",
    "f_scores = []\n",
    "\n",
    "for train_ix, valid_ix in kfold.split(X, y):\n",
    "    X_train, X_valid = X.loc[train_ix], X.loc[valid_ix]\n",
    "    y_train, y_valid = y.loc[train_ix], y.loc[valid_ix]\n",
    "    \n",
    "    \n",
    "    X_train_extended = split_frames_to_windows(ts_frames, window_size=window_size)\n",
    "    X_train_extended = X_train_extended.reshape(len(X_train_extended), -1)\n",
    "    y_train_extended = np.tile(y_train, n_windows)\n",
    "    \n",
    "    cls = svm.SVC()\n",
    "    cls.fit(X_train_extended, y_train_extended)\n",
    "    X_valid_extended = assemble_ts_parts(X_valid)\n",
    "    X_valid_extended = split_frames_to_windows(X_valid_extended, window_size=window_size)\n",
    "    X_valid_extended = X_valid_extended.reshape(len(X_valid_extended), -1)\n",
    "    \n",
    "    y_pred_extended = cls.predict(X_valid_extended)\n",
    "    y_pred = fold_predictions(y_pred_extended, n_windows=n_windows)\n",
    "    y_pred = y_pred > threshold\n",
    "    f_scores.append(f1_score(y_valid, y_pred))\n",
    "    \n",
    "print(f'F1 score mean: {round(np.mean(f_scores), 2)}, std: {round(np.std(f_scores), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score mean: 0.64, std: 0.07\n"
     ]
    }
   ],
   "source": [
    "X = df[[str(i) for i in range(90)] ]\n",
    "y = df['is_stairs']\n",
    "\n",
    "f_scores = []\n",
    "\n",
    "for train_ix, valid_ix in kfold.split(X, y):\n",
    "    X_train, X_valid = X.loc[train_ix], X.loc[valid_ix]\n",
    "    y_train, y_valid = y.loc[train_ix], y.loc[valid_ix]\n",
    "    cls = svm.SVC()\n",
    "    cls.fit(X_train, y_train)\n",
    "    y_pred = cls.predict(X_valid)\n",
    "    f_scores.append(f1_score(y_valid, y_pred))\n",
    "    \n",
    "print(f'F1 score mean: {round(np.mean(f_scores), 2)}, std: {round(np.std(f_scores), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score mean: 0.64, std: 0.07\n"
     ]
    }
   ],
   "source": [
    "X = np.hstack([X[x_acc_cols].values, X[y_acc_cols].values, X[z_acc_cols].values ])\n",
    "\n",
    "y = df['is_stairs']\n",
    "\n",
    "f_scores = []\n",
    "\n",
    "for train_ix, valid_ix in kfold.split(X, y):\n",
    "    X_train, X_valid = X[train_ix], X[valid_ix]\n",
    "    y_train, y_valid = y[train_ix], y[valid_ix]\n",
    "    cls = svm.SVC()\n",
    "    cls.fit(X_train, y_train)\n",
    "    y_pred = cls.predict(X_valid)\n",
    "    f_scores.append(f1_score(y_valid, y_pred))\n",
    "    \n",
    "print(f'F1 score mean: {round(np.mean(f_scores), 2)}, std: {round(np.std(f_scores), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score mean: 0.64, std: 0.07\n"
     ]
    }
   ],
   "source": [
    "window_size = 30\n",
    "threshold = .5\n",
    "n_windows = FRAME_LENGTH - window_size + 1\n",
    "\n",
    "X = df[[str(i) for i in range(90)] ]\n",
    "y = df['is_stairs']\n",
    "\n",
    "f_scores = []\n",
    "\n",
    "for train_ix, valid_ix in kfold.split(X, y):\n",
    "    X_train, X_valid = X.loc[train_ix], X.loc[valid_ix]\n",
    "    y_train, y_valid = y.loc[train_ix], y.loc[valid_ix]\n",
    "    \n",
    "    ts_frames = assemble_ts_parts(X_train)\n",
    "    X_train_extended = split_frames_to_windows(ts_frames, window_size=window_size)\n",
    "    X_train_extended = X_train_extended.reshape(len(X_train_extended), -1)\n",
    "    y_train_extended = np.tile(y_train, n_windows)\n",
    "    \n",
    "    cls = svm.SVC()\n",
    "    cls.fit(X_train_extended, y_train_extended)\n",
    "    X_valid_extended = assemble_ts_parts(X_valid)\n",
    "    X_valid_extended = split_frames_to_windows(X_valid_extended, window_size=window_size)\n",
    "    X_valid_extended = X_valid_extended.reshape(len(X_valid_extended), -1)\n",
    "    \n",
    "    y_pred_extended = cls.predict(X_valid_extended)\n",
    "    y_pred = fold_predictions(y_pred_extended, n_windows=n_windows)\n",
    "    y_pred = y_pred > threshold\n",
    "    f_scores.append(f1_score(y_valid, y_pred))\n",
    "    \n",
    "print(f'F1 score mean: {round(np.mean(f_scores), 2)}, std: {round(np.std(f_scores), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score mean: 0.64, std: 0.07\n"
     ]
    }
   ],
   "source": [
    "window_size = 29\n",
    "threshold = .5\n",
    "n_windows = FRAME_LENGTH - window_size + 1\n",
    "\n",
    "X = df[[str(i) for i in range(90)] ]\n",
    "y = df['is_stairs']\n",
    "\n",
    "f_scores = []\n",
    "\n",
    "for train_ix, valid_ix in kfold.split(X, y):\n",
    "    X_train, X_valid = X.loc[train_ix], X.loc[valid_ix]\n",
    "    y_train, y_valid = y.loc[train_ix], y.loc[valid_ix]\n",
    "    \n",
    "    ts_frames = assemble_ts_parts(X_train)\n",
    "    X_train_extended = split_frames_to_windows(ts_frames, window_size=window_size)\n",
    "    X_train_extended = X_train_extended.reshape(len(X_train_extended), -1)\n",
    "    y_train_extended = np.tile(y_train, n_windows)\n",
    "    \n",
    "    cls = svm.SVC()\n",
    "    cls.fit(X_train_extended, y_train_extended)\n",
    "    X_valid_extended = assemble_ts_parts(X_valid)\n",
    "    X_valid_extended = split_frames_to_windows(X_valid_extended, window_size=window_size)\n",
    "    X_valid_extended = X_valid_extended.reshape(len(X_valid_extended), -1)\n",
    "    \n",
    "    y_pred_extended = cls.predict(X_valid_extended)\n",
    "    y_pred = fold_predictions(y_pred_extended, n_windows=n_windows)\n",
    "    y_pred = y_pred > threshold\n",
    "    f_scores.append(f1_score(y_valid, y_pred))\n",
    "    \n",
    "print(f'F1 score mean: {round(np.mean(f_scores), 2)}, std: {round(np.std(f_scores), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score mean: 0.9, std: 0.04\n"
     ]
    }
   ],
   "source": [
    "window_size = 20\n",
    "threshold = .5\n",
    "n_windows = FRAME_LENGTH - window_size + 1\n",
    "\n",
    "X = df[[str(i) for i in range(90)] ]\n",
    "y = df['is_stairs']\n",
    "\n",
    "f_scores = []\n",
    "\n",
    "for train_ix, valid_ix in kfold.split(X, y):\n",
    "    X_train, X_valid = X.loc[train_ix], X.loc[valid_ix]\n",
    "    y_train, y_valid = y.loc[train_ix], y.loc[valid_ix]\n",
    "    \n",
    "    ts_frames = assemble_ts_parts(X_train)\n",
    "    X_train_extended = split_frames_to_windows(ts_frames, window_size=window_size)\n",
    "    X_train_extended = X_train_extended.reshape(len(X_train_extended), -1)\n",
    "    y_train_extended = np.tile(y_train, n_windows)\n",
    "    \n",
    "    cls = svm.SVC()\n",
    "    cls.fit(X_train_extended, y_train_extended)\n",
    "    X_valid_extended = assemble_ts_parts(X_valid)\n",
    "    X_valid_extended = split_frames_to_windows(X_valid_extended, window_size=window_size)\n",
    "    X_valid_extended = X_valid_extended.reshape(len(X_valid_extended), -1)\n",
    "    \n",
    "    y_pred_extended = cls.predict(X_valid_extended)\n",
    "    y_pred = fold_predictions(y_pred_extended, n_windows=n_windows)\n",
    "    y_pred = y_pred > threshold\n",
    "    f_scores.append(f1_score(y_valid, y_pred))\n",
    "    \n",
    "print(f'F1 score mean: {round(np.mean(f_scores), 2)}, std: {round(np.std(f_scores), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_ts_parts_arr(X):\n",
    "    x_part = X[:, np.arange(30)]\n",
    "    y_part = X[:, np.arange(30, 60)]\n",
    "    z_part = X[:, np.arange(60, 90)]\n",
    "    features = np.stack([x_part, y_part, z_part], axis=1)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FramingSVMClassifier:\n",
    "    def __init__(self, window_size, frame_length=FRAME_LENGTH):\n",
    "        self.window_size  = window_size\n",
    "        self.frame_length = frame_length\n",
    "        self.n_windows    = frame_length - window_size + 1\n",
    "        self.threshold = .5\n",
    "        \n",
    "    def expand_X(self, X):\n",
    "        X_expanded = assemble_ts_parts_arr(X)\n",
    "        X_expanded = split_frames_to_windows(X_expanded, window_size=self.window_size)\n",
    "        X_expanded = X_expanded.reshape(len(X_expanded), -1)\n",
    "        return X_expanded\n",
    "    \n",
    "    def expand_y(self, y):\n",
    "        return np.tile(y, self.n_windows)\n",
    "    \n",
    "    def fold_preds(self, y_expanded):\n",
    "        y_pred = fold_predictions(y_expanded, n_windows=self.n_windows)\n",
    "        return y_pred\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X_expanded = self.expand_X(X)\n",
    "        y_expanded = self.expand_y(y)\n",
    "        self.cls = svm.SVC()\n",
    "        self.cls.fit(X_expanded, y_expanded)\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        X_expanded = self.expand_X(X)\n",
    "        y_expanded = self.cls.predict(X_expanded)\n",
    "        y_pred = self.fold_preds(y_expanded)\n",
    "        return y_pred\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        y_average = self.predict_proba(X)\n",
    "        return y_average >= self.threshold\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FramingTransformer:\n",
    "    def __init__(self, window_size, frame_length=FRAME_LENGTH):\n",
    "        self.window_size  = window_size\n",
    "        self.frame_length = frame_length\n",
    "        self.n_windows    = frame_length - window_size + 1\n",
    "#         self.threshold = .5\n",
    "        \n",
    "    def expand_X(self, X):\n",
    "        X_expanded = X.reshape(len(X), -1, self.frame_length)#assemble_ts_parts_arr(X)\n",
    "        X_expanded = split_frames_to_windows(X_expanded, window_size=self.window_size)\n",
    "        X_expanded = X_expanded.reshape(len(X_expanded), -1)\n",
    "        return X_expanded\n",
    "    \n",
    "    def expand_y(self, y):\n",
    "        return np.tile(y, self.n_windows)\n",
    "    \n",
    "    def fold_preds(self, y_expanded):\n",
    "        y_pred = fold_predictions(y_expanded, n_windows=self.n_windows)\n",
    "        return y_pred\n",
    "        \n",
    "    def expand(self, X, y=None):\n",
    "        X_expanded = self.expand_X(X)\n",
    "        if y is not None:\n",
    "            y_expanded = self.expand_y(y)\n",
    "            return X_expanded, y_expanded\n",
    "        return X_expanded\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "frm = FramingTransformer(window_size=2, frame_length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 3, 4, 0, 1, 3],\n",
       "       [5, 0, 0, 1, 4, 5]])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "sample_y = np.array([1, 0])\n",
    "sample_X = np.random.randint(6, size=(2,6))\n",
    "sample_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 3, 0, 1],\n",
       "       [5, 0, 1, 4],\n",
       "       [3, 4, 1, 3],\n",
       "       [0, 0, 4, 5]])"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frm.expand_X(sample_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5, 3, 0, 1],\n",
       "        [5, 0, 1, 4],\n",
       "        [3, 4, 1, 3],\n",
       "        [0, 0, 4, 5]]),\n",
       " array([1, 0, 1, 0]))"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frm.expand(sample_X, sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_expanded = split_frames_to_windows(X_expanded, window_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 2)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_expanded.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frm.n_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 3, 4, 0, 1, 3],\n",
       "       [5, 0, 0, 1, 4, 5]])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([df[x_acc_cols].values, df[y_acc_cols].values, df[z_acc_cols].values ])\n",
    "train_ix, valid_ix = list(kfold.split(X, y))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = X[train_ix], X[valid_ix]\n",
    "y_train, y_valid = y[train_ix], y[valid_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "cls = svm.SVC()\n",
    "cls.fit(X_train, y_train)\n",
    "y_pred = cls.predict(X_valid)\n",
    "print(f1_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "cls = FramingSVMClassifier(window_size=30)\n",
    "cls.fit(X_train, y_train)\n",
    "y_pred = cls.predict(X_valid)\n",
    "print(f1_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_expanded = cls.expand_X(X)\n",
    "y_expanded = cls.expand_y(y)\n",
    "svm_cls = svm.SVC()\n",
    "svm_cls.fit(X_expanded, y_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4030, 87)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_expanded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4030,)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_expanded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2015, 180)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_expanded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3224, 87)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.expand_X(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15151515151515152\n"
     ]
    }
   ],
   "source": [
    "cls = FramingSVMClassifier(window_size=25)\n",
    "cls.fit(X_train, y_train)\n",
    "y_pred = cls.predict(X_valid)\n",
    "print(f1_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[342,  28],\n",
       "       [ 28,   5]])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 1. , 0.5, 0.5, 0.5, 1. , 1. , 0.5, 0.5, 0.5, 0. , 1. , 0. ,\n",
       "       1. , 1. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0. , 0.5, 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0.5, 1. , 1. , 0.5, 0.5, 1. , 1. ,\n",
       "       0.5, 1. , 0.5, 0. , 0.5, 0. , 0.5, 1. , 0.5, 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0.5, 0. , 0. , 0. , 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True,  True, False,  True, False,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "        True, False, False, False,  True,  True, False, False,  True,\n",
       "        True,  True,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_frames = assemble_ts_parts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.675165\n",
       "1    -11.607090\n",
       "2     -2.662352\n",
       "3     -1.278504\n",
       "4     -2.700659\n",
       "        ...    \n",
       "85    -6.320692\n",
       "86     9.255983\n",
       "87     1.747767\n",
       "88     2.920926\n",
       "89     7.910443\n",
       "Name: 0, Length: 90, dtype: float64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.675165,  -1.278504,  -4.424484,   0.646435,  -1.623269,\n",
       "         -4.323928,  -5.228936,  -3.08852 ,  -3.021482, -11.238382,\n",
       "         -0.488417,  -7.675811,  -0.521936,  -3.715801,  -1.666364,\n",
       "         -6.354211,  -3.940856,  -1.240196, -10.228029,  -1.043872,\n",
       "         -6.411672, -10.070012,  -7.929596,  -1.929727,  -4.458003,\n",
       "         -4.13718 ,   1.82917 ,  -7.350199,   3.969586,   1.747767],\n",
       "       [-11.60709 ,  -2.700659, -10.726024,  -0.641646,  -6.603208,\n",
       "         -2.671929,  -3.557784, -14.130578,  -8.39886 , -12.018892,\n",
       "         -9.356541, -17.00362 ,   0.708684,  -5.645528,  -9.121908,\n",
       "         -5.717354, -12.717999, -10.414778, -14.465767, -13.603854,\n",
       "        -11.836933, -15.049952, -12.253524,  -2.806004,  -6.780379,\n",
       "         -4.429273,  -9.313444, -12.670115,  -6.320692,   2.920926],\n",
       "       [ -2.662352,   0.924162,  -1.082179,  -1.04866 ,   0.071826,\n",
       "          3.485958,  -0.038307,   0.215478,   1.312023,  -2.762909,\n",
       "          0.11971 ,  -1.546654,  -5.051765,   0.670377,  -2.753332,\n",
       "         -0.579397,   5.971139,  -1.173159,  -1.867477,  -3.600879,\n",
       "         -3.883395, -13.517663,  -0.263362,  -1.795651,   1.580173,\n",
       "         -1.517924,  -0.3304  ,  -1.460463,   9.255983,   7.910443]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
